{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>512.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass   Age  SibSp  Parch  Fare\n",
       "count        891.0     891.0   891.0 714.0  891.0  891.0 891.0\n",
       "mean         446.0       0.4     2.3  29.7    0.5    0.4  32.2\n",
       "std          257.4       0.5     0.8  14.5    1.1    0.8  49.7\n",
       "min            1.0       0.0     1.0   0.4    0.0    0.0   0.0\n",
       "25%          223.5       0.0     2.0  20.1    0.0    0.0   7.9\n",
       "50%          446.0       0.0     3.0  28.0    0.0    0.0  14.5\n",
       "75%          668.5       1.0     3.0  38.0    1.0    0.0  31.0\n",
       "max          891.0       1.0     3.0  80.0    8.0    6.0 512.3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "titanic_dataframe = pd.read_csv(\"titanic/train.csv\", sep=\",\")\n",
    "\n",
    "titanic_dataframe = titanic_dataframe.reindex(\n",
    "    np.random.permutation(titanic_dataframe.index))\n",
    "\n",
    "titanic_dataframe.describe()\n",
    "\n",
    "# titanic_dataframe = titanic_dataframe[titanic_dataframe[\"TotRmsAbvGrd\"] <= 13]\n",
    "# titanic_dataframe = titanic_dataframe[titanic_dataframe[\"OverallQual\"] <= 9.5]\n",
    "# titanic_dataframe = titanic_dataframe[titanic_dataframe[\"GrLivArea\"] <= 3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_features(titanic_dataframe, drop):#, features):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    titanic_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "\n",
    "  processed_features = pd.DataFrame()\n",
    "  processed_features['Fare'] = titanic_dataframe['Fare']\n",
    "\n",
    "  return processed_features\n",
    "\n",
    "def preprocess_targets(titanic_dataframe):\n",
    "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    titanic_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the target feature.\n",
    "  \"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  output_targets[\"Survived\"] = titanic_dataframe[\"Survived\"]\n",
    "  return output_targets\n",
    "# titanic_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the first 12000 (out of 17000) examples for training.\n",
    "training_examples = preprocess_features(titanic_dataframe.head(691), 0)\n",
    "training_targets = preprocess_targets(titanic_dataframe.head(691))\n",
    "\n",
    "# Choose the last 5000 (out of 17000) examples for validation.\n",
    "validation_examples = preprocess_features(titanic_dataframe.tail(460), 0)#, features1)\n",
    "validation_targets = preprocess_targets(titanic_dataframe.tail(460))\n",
    "\n",
    "# display.display(titanic_dataframe.describe())\n",
    "\n",
    "# # Double-check that we've done the right thing.\n",
    "# print(\"Training examples summary:\")\n",
    "# display.display(training_examples.describe())\n",
    "# print(\"Validation examples summary:\")\n",
    "# display.display(validation_examples.describe())\n",
    "\n",
    "# print(\"Training targets summary:\")\n",
    "# display.display(training_targets.describe())\n",
    "# print(\"Validation targets summary:\")\n",
    "# display.display(validation_targets.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    "    \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns(input_features):\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Args:\n",
    "    input_features: The names of the numerical input features to use.\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\" \n",
    "  return set([tf.feature_column.numeric_column(my_feature)\n",
    "              for my_feature in input_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_scale(series):\n",
    "  min_val = series.min()\n",
    "  max_val = series.max()\n",
    "  scale = (max_val - min_val) / 2.0\n",
    "  return series.apply(lambda x:((x - min_val) / scale) - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_linear_regressor_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear regression model.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  as well as a plot of the training and validation loss over time.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for training.\n",
    "    training_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for training.\n",
    "    validation_examples: A `DataFrame` containing one or more columns from\n",
    "      `california_housing_dataframe` to use as input features for validation.\n",
    "    validation_targets: A `DataFrame` containing exactly one column from\n",
    "      `california_housing_dataframe` to use as target for validation.\n",
    "      \n",
    "  Returns:\n",
    "    A `LinearRegressor` object trained on the training data.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  # Create a linear regressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=construct_feature_columns(training_examples),\n",
    "      optimizer=my_optimizer\n",
    "  )\n",
    "    \n",
    "  # Create input functions.\n",
    "  training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                          training_targets[\"Survived\"], \n",
    "                                          batch_size=batch_size)\n",
    "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                                  training_targets[\"Survived\"], \n",
    "                                                  num_epochs=1, \n",
    "                                                  shuffle=False)\n",
    "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                                    validation_targets[\"Survived\"], \n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"RMSE (on training data):\")\n",
    "  training_rmse = []\n",
    "  validation_rmse = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    \n",
    "    # Take a break and compute predictions.\n",
    "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
    "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "    \n",
    "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "    \n",
    "    # Compute training and validation loss.\n",
    "    training_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(training_predictions, training_targets))\n",
    "    validation_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_rmse.append(training_root_mean_squared_error)\n",
    "    validation_rmse.append(validation_root_mean_squared_error)\n",
    "  print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"RMSE\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(training_rmse, label=\"training\")\n",
    "  plt.plot(validation_rmse, label=\"validation\")\n",
    "  plt.legend()\n",
    "\n",
    "  return linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.61\n",
      "  period 01 : 0.61\n",
      "  period 02 : 0.61\n",
      "  period 03 : 0.61\n",
      "  period 04 : 0.60\n",
      "  period 05 : 0.60\n",
      "  period 06 : 0.60\n",
      "  period 07 : 0.59\n",
      "  period 08 : 0.59\n",
      "  period 09 : 0.59\n",
      "Model training finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEbCAYAAABUV7o5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d146447b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regressor = train_linear_regressor_model(\n",
    "    learning_rate=0.000001,\n",
    "    steps=200,\n",
    "    batch_size=20,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def train_linear_classification_model(#def train_nn_regression_model(\n",
    "#     my_optimizer,\n",
    "#     steps,\n",
    "#     batch_size,\n",
    "#     training_examples,\n",
    "#     training_targets,\n",
    "#     validation_examples,\n",
    "#     validation_targets):\n",
    "\n",
    "#   periods = 10\n",
    "#   steps_per_period = steps / periods\n",
    "  \n",
    "#   # Create a DNNRegressor object.\n",
    "#   my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "#   dnn_regressor = tf.estimator.LinearClassifier(\n",
    "#       feature_columns = construct_feature_columns(training_examples),\n",
    "# #       hidden_units=hidden_units,\n",
    "#       optimizer=my_optimizer\n",
    "#   )\n",
    "  \n",
    "#   # Create input functions.\n",
    "#   training_input_fn = lambda: my_input_fn(training_examples, \n",
    "#                                           training_targets[\"Survived\"], \n",
    "#                                           batch_size=batch_size)\n",
    "#   predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
    "#                                                   training_targets[\"Survived\"], \n",
    "#                                                   num_epochs=1, \n",
    "#                                                   shuffle=False)\n",
    "#   predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "#                                                     validation_targets[\"Survived\"], \n",
    "#                                                     num_epochs=1, \n",
    "#                                                     shuffle=False)\n",
    "\n",
    "#   # Train the model, but do so inside a loop so that we can periodically assess\n",
    "#   # loss metrics.\n",
    "#   print(\"Training model...\")\n",
    "#   print(\"RMSE (on training data):\")\n",
    "#   training_rmse = []\n",
    "#   validation_rmse = []\n",
    "#   for period in range (0, periods):\n",
    "#     # Train the model, starting from the prior state.\n",
    "#     dnn_regressor.train(\n",
    "#         input_fn=training_input_fn,\n",
    "#         steps=steps_per_period\n",
    "#     )\n",
    "# #     Take a break and compute predictions.\n",
    "#     training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
    "#     training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "    \n",
    "#     validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "#     validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "    \n",
    "#     # Compute training and validation loss.\n",
    "#     training_root_mean_squared_error = math.sqrt(\n",
    "#         metrics.mean_squared_error(training_predictions, training_targets))\n",
    "#     validation_root_mean_squared_error = math.sqrt(\n",
    "#         metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "#     # Occasionally print the current loss.\n",
    "#     print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "#     # Add the loss metrics from this period to our list.\n",
    "#     training_rmse.append(training_root_mean_squared_error)\n",
    "#     validation_rmse.append(validation_root_mean_squared_error)\n",
    "#   print(\"Model training finished.\")\n",
    "\n",
    "# #   # Output a graph of loss metrics over periods.\n",
    "#   plt.ylabel(\"RMSE\")\n",
    "#   plt.xlabel(\"Periods\")\n",
    "#   plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "#   plt.tight_layout()\n",
    "#   plt.plot(training_rmse, label=\"training\")\n",
    "#   plt.plot(validation_rmse, label=\"validation\")\n",
    "#   plt.legend()\n",
    "\n",
    "#   print(\"Final RMSE (on training data):   %0.2f\" % training_root_mean_squared_error)\n",
    "#   print(\"Final RMSE (on validation data): %0.2f\" % validation_root_mean_squared_error)\n",
    "\n",
    "#   return dnn_regressor, training_rmse, validation_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-26b3c031ad77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m              \u001b[0mtraining_targets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#.ix[index1],\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m              \u001b[0mvalidation_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#normalized_validation_examples,#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m              validation_targets=validation_targets)#.ix[index2])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-f6715e12fac2>\u001b[0m in \u001b[0;36mtrain_linear_classification_model\u001b[1;34m(my_optimizer, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#     Take a break and compute predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mtraining_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_training_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mtraining_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_validation_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f6715e12fac2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#     Take a break and compute predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mtraining_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_training_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mtraining_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_validation_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predictions'"
     ]
    }
   ],
   "source": [
    "# classifier = train_linear_classification_model(\n",
    "#              my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.005),\n",
    "# #              learning_rate=0.002,\n",
    "#              steps=1000,\n",
    "#              batch_size=10,\n",
    "#              training_examples=training_examples,#normalized_training_examples,#\n",
    "#              training_targets=training_targets,#.ix[index1],\n",
    "#              validation_examples=validation_examples,#normalized_validation_examples,#\n",
    "#              validation_targets=validation_targets)#.ix[index2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
