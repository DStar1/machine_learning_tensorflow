{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = 10 # Number of different types of labels (1-10)\n",
    "WIDTH = 28 # width / height of the image\n",
    "CHANNELS = 1 # Number of colors in the image (greyscale)\n",
    "\n",
    "VALID = 10000 # Validation data size\n",
    "\n",
    "STEPS = 3500 #20000#   # Number of steps to run\n",
    "BATCH = 100 # Stochastic Gradient Descent batch size\n",
    "PATCH = 5 # Convolutional Kernel size\n",
    "DEPTH = 8 #32 # Convolutional Kernel depth size == Number of Convolutional Kernels\n",
    "HIDDEN = 100 #1024 # Number of hidden neurons in the fully connected layer\n",
    "\n",
    "LR = 0.001 # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape = (32000, 28, 28, 1) = (TRAIN, WIDTH, WIDTH, CHANNELS)\n",
      "labels shape = (42000, 10) = (TRAIN, LABELS)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv') # Read csv file in pandas dataframe\n",
    "labels = np.array(data.pop('label')) # Remove the labels as a numpy array from the dataframe\n",
    "labels = LabelEncoder().fit_transform(labels)[:, None]\n",
    "labels = OneHotEncoder().fit_transform(labels).todense()\n",
    "data = StandardScaler().fit_transform(np.float32(data.values)) # Convert the dataframe to a numpy array\n",
    "data = data.reshape(-1, WIDTH, WIDTH, CHANNELS) # Reshape the data into 42000 2d images\n",
    "train_data, valid_data = data[:-VALID], data[-VALID:]\n",
    "train_labels, valid_labels = labels[:-VALID], labels[-VALID:]\n",
    "\n",
    "print('train data shape = ' + str(train_data.shape) + ' = (TRAIN, WIDTH, WIDTH, CHANNELS)')\n",
    "print('labels shape = ' + str(labels.shape) + ' = (TRAIN, LABELS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_data = tf.placeholder(tf.float32, shape=(None, WIDTH, WIDTH, CHANNELS))\n",
    "tf_labels = tf.placeholder(tf.float32, shape=(None, LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00487956]\n",
      "   ...\n",
      "   [-0.00805699]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [-0.00796544]\n",
      "   ...\n",
      "   [-0.00678334]\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [-0.00487956]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]\n",
      "\n",
      "  [[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   ...\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/2\")#imagenet/inception_v3/feature_vector/1\")\n",
    "# input_layer = adjust_image(train_data)\n",
    "# outputs = module(input_layer)\n",
    "\n",
    "# logits = tf.layers.dense(inputs=outputs, units=10)\n",
    "# tf_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w1 = tf.Variable(tf.truncated_normal([PATCH, PATCH, CHANNELS, DEPTH], stddev=0.1))\n",
    "# b1 = tf.Variable(tf.zeros([DEPTH]))\n",
    "# w2 = tf.Variable(tf.truncated_normal([PATCH, PATCH, DEPTH, 2*DEPTH], stddev=0.1))\n",
    "# b2 = tf.Variable(tf.constant(1.0, shape=[2*DEPTH]))\n",
    "# w3 = tf.Variable(tf.truncated_normal([WIDTH // 4 * WIDTH // 4 * 2*DEPTH, HIDDEN], stddev=0.1))\n",
    "# b3 = tf.Variable(tf.constant(1.0, shape=[HIDDEN]))\n",
    "# w4 = tf.Variable(tf.truncated_normal([HIDDEN, LABELS], stddev=0.1))\n",
    "# b4 = tf.Variable(tf.constant(1.0, shape=[LABELS]))\n",
    "\n",
    "# def logits(data):\n",
    "#     # Convolutional layer 1\n",
    "#     x = tf.nn.conv2d(data, w1, [1, 1, 1, 1], padding='SAME')\n",
    "#     x = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "#     x = tf.nn.relu(x + b1)\n",
    "#     # Convolutional layer 2\n",
    "#     x = tf.nn.conv2d(x, w2, [1, 1, 1, 1], padding='SAME')\n",
    "#     x = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "#     x = tf.nn.relu(x + b2)\n",
    "#     # Fully connected layer\n",
    "#     x = tf.reshape(x, (-1, WIDTH // 4 * WIDTH // 4 * 2*DEPTH))\n",
    "#     x = tf.nn.relu(tf.matmul(x, w3) + b3)\n",
    "#     return tf.matmul(x, w4) + b4\n",
    "\n",
    "# # Prediction:\n",
    "# tf_pred = tf.nn.softmax(logits(tf_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                 labels=tf_labels))\n",
    "tf_acc = 100*tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(tf_pred, 1), tf.argmax(tf_labels, 1))))\n",
    "\n",
    "#tf_opt = tf.train.GradientDescentOptimizer(LR)\n",
    "#tf_opt = tf.train.AdamOptimizer(LR)\n",
    "tf_opt = tf.train.RMSPropOptimizer(LR)\n",
    "tf_step = tf_opt.minimize(tf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harrisonfsmith95/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 \t Valid. Acc. = 95.850006\n",
      "Step 1000 \t Valid. Acc. = 97.669998\n",
      "Step 1500 \t Valid. Acc. = 98.119995\n",
      "Step 2000 \t Valid. Acc. = 98.299995\n",
      "Step 2500 \t Valid. Acc. = 98.509995\n",
      "Step 3000 \t Valid. Acc. = 98.189995\n",
      "Step 3500 \t Valid. Acc. = 98.629997\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=STEPS, train_size=BATCH)\n",
    "ss.get_n_splits(train_data, train_labels)\n",
    "history = [(0, np.nan, 10)] # Initial Error Measures\n",
    "for step, (idx, _) in enumerate(ss.split(train_data,train_labels), start=1):\n",
    "    fd = {tf_data:train_data[idx], tf_labels:train_labels[idx]}\n",
    "    session.run(tf_step, feed_dict=fd)\n",
    "    if step%500 == 0:\n",
    "        fd = {tf_data:valid_data, tf_labels:valid_labels}\n",
    "        valid_loss, valid_accuracy = session.run([tf_loss, tf_acc], feed_dict=fd)\n",
    "        history.append((step, valid_loss, valid_accuracy))\n",
    "        print('Step %i \\t Valid. Acc. = %f'%(step, valid_accuracy), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEKCAYAAABZr/GWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90e03c3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps, loss, acc = zip(*history)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('Validation Loss / Accuracy')\n",
    "ax_loss = fig.add_subplot(111)\n",
    "ax_acc = ax_loss.twinx()\n",
    "plt.xlabel('Training Steps')\n",
    "plt.xlim(0, max(steps))\n",
    "\n",
    "ax_loss.plot(steps, loss, '-o', color='blue')\n",
    "ax_loss.set_ylabel('Log Loss', color='blue');\n",
    "ax_loss.tick_params('y', colors='blue')\n",
    "ax_loss.set_ylim(0.01, 0.5)\n",
    "\n",
    "ax_acc.plot(steps, acc, '-o', color='red')\n",
    "ax_acc.set_ylabel('Accuracy [%]', color='red');\n",
    "ax_acc.tick_params('y', colors='red')\n",
    "ax_acc.set_ylim(1,100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv') # Read csv file in pandas dataframe\n",
    "test_data = StandardScaler().fit_transform(np.float32(test.values)) # Convert the dataframe to a numpy array\n",
    "test_data = test_data.reshape(-1, WIDTH, WIDTH, CHANNELS) # Reshape the data into 42000 2d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = session.run(tf_pred, feed_dict={tf_data:test_data})\n",
    "test_labels = np.argmax(test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fd = {tf_data:valid_test_data, tf_labels:valid_test_labels}\n",
    "# valid_loss, valid_accuracy = session.run([tf_loss, tf_acc], feed_dict=fd)\n",
    "# print('Valid. Acc. = %f'% test_pred, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k = 2 # Try different image indices k\n",
    "# print(\"Label Prediction: %i\"%test_labels[k])\n",
    "# fig = plt.figure(figsize=(2,2)); plt.axis('off')\n",
    "# plt.imshow(test_data[k,:,:,0]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(data={'ImageId':(np.arange(test_labels.shape[0])+1), 'Label':test_labels})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
