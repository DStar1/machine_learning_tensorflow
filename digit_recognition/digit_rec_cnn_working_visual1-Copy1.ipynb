{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8843</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "4773      9       0       0       0       0       0       0       0       0   \n",
       "1384      7       0       0       0       0       0       0       0       0   \n",
       "1655      6       0       0       0       0       0       0       0       0   \n",
       "8843      6       0       0       0       0       0       0       0       0   \n",
       "5917      6       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "4773       0    ...            0         0         0         0         0   \n",
       "1384       0    ...            0         0         0         0         0   \n",
       "1655       0    ...            0         0         0         0         0   \n",
       "8843       0    ...            0         0         0         0         0   \n",
       "5917       0    ...            0         0         0         0         0   \n",
       "\n",
       "      pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "4773         0         0         0         0         0  \n",
       "1384         0         0         0         0         0  \n",
       "1655         0         0         0         0         0  \n",
       "8843         0         0         0         0         0  \n",
       "5917         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "mnist_dataframe = pd.read_csv(\"data/train.csv\", sep=\",\")\n",
    "\n",
    "# Use just the first 10,000 records for training/validation.\n",
    "mnist_dataframe = mnist_dataframe.head(10000)\n",
    "\n",
    "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
    "mnist_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8743</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel71\n",
       "4773        0\n",
       "1384        0\n",
       "1655        0\n",
       "8843        0\n",
       "5917        0\n",
       "...       ...\n",
       "1693        0\n",
       "8743        0\n",
       "6442        0\n",
       "4111        0\n",
       "6174        0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataframe.iloc[:, 72:73]#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_labels_and_features(dataset):\n",
    "  \"\"\"Extracts labels and features.\n",
    "  \n",
    "  This is a good place to scale or transform the features if needed.\n",
    "  \n",
    "  Args:\n",
    "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
    "      monochrome pixel values on the remaining columns, in row major order.\n",
    "  Returns:\n",
    "    A `tuple` `(labels, features)`:\n",
    "      labels: A Pandas `Series`.\n",
    "      features: A Pandas `DataFrame`.\n",
    "  \"\"\"\n",
    "  labels = dataset['label']\n",
    "\n",
    "  # DataFrame.loc index ranges are inclusive at both ends.\n",
    "  features = dataset.iloc[:,1:785]\n",
    "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
    "#   features = features // 255\n",
    "  features = features.applymap(lambda x: x / 255)\n",
    "\n",
    "  return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_test_labels_and_features(labels1, dataset):\n",
    "  \"\"\"Extracts labels and features.\n",
    "  \n",
    "  This is a good place to scale or transform the features if needed.\n",
    "  \n",
    "  Args:\n",
    "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
    "      monochrome pixel values on the remaining columns, in row major order.\n",
    "  Returns:\n",
    "    A `tuple` `(labels, features)`:\n",
    "      labels: A Pandas `Series`.\n",
    "      features: A Pandas `DataFrame`.\n",
    "  \"\"\"\n",
    "  labels = labels1['Label']\n",
    "\n",
    "  # DataFrame.loc index ranges are inclusive at both ends.\n",
    "  features = dataset.copy()\n",
    "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
    "#   features = features // 255\n",
    "#   features = features.applymap(lambda x: x / 255)\n",
    "\n",
    "  return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "4773     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1384     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1655     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8843     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5917     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "4617     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2353     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3415     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4471     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "159      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "4773     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "1384     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "1655     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "8843     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "5917     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "...      ...    ...          ...       ...       ...       ...       ...   \n",
       "4617     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "2353     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "3415     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "4471     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "159      0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "4773       0.0       0.0       0.0       0.0       0.0  \n",
       "1384       0.0       0.0       0.0       0.0       0.0  \n",
       "1655       0.0       0.0       0.0       0.0       0.0  \n",
       "8843       0.0       0.0       0.0       0.0       0.0  \n",
       "5917       0.0       0.0       0.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "4617       0.0       0.0       0.0       0.0       0.0  \n",
       "2353       0.0       0.0       0.0       0.0       0.0  \n",
       "3415       0.0       0.0       0.0       0.0       0.0  \n",
       "4471       0.0       0.0       0.0       0.0       0.0  \n",
       "159        0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[7500 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
    "training_examples#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "count  2500.0  2500.0  2500.0  2500.0  2500.0  2500.0  2500.0  2500.0  2500.0   \n",
       "mean      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "std       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "min       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "25%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "50%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "75%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "max       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "count  2500.0    ...       2500.0    2500.0    2500.0    2500.0    2500.0   \n",
       "mean      0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "std       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "min       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "25%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "50%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "75%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "max       0.0    ...          0.7       1.0       0.5       0.0       0.0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "count    2500.0    2500.0    2500.0    2500.0    2500.0  \n",
       "mean        0.0       0.0       0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
    "validation_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEHCAYAAACOfPs0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdec5c79f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_example = np.random.choice(training_examples.index)\n",
    "_, ax = plt.subplots()\n",
    "# ax.imshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
    "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
    "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\" \n",
    "  \n",
    "  # There are 784 pixels in each image.\n",
    "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
    "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
    "\n",
    "  Args:\n",
    "    features: The training features.\n",
    "    labels: The training labels.\n",
    "    batch_size: Batch size to use during training.\n",
    "\n",
    "  Returns:\n",
    "    A function that returns batches of training features and labels during\n",
    "    training.\n",
    "  \"\"\"\n",
    "  def _input_fn(num_epochs=None, shuffle=True):\n",
    "        \n",
    "#     tf.estimator.inputs.numpy_input_fn(               x={\"x\": train_data},\n",
    "#                                                       y=train_labels,\n",
    "#                                                       batch_size=batch_\n",
    "        \n",
    "        \n",
    "    # Input pipelines are reset with each call to .train(). To ensure model\n",
    "    # gets a good sampling of data, even when number of steps is small, we \n",
    "    # shuffle all the data before creating the Dataset object\n",
    "    idx = np.random.permutation(features.index)\n",
    "    raw_features = {\"x\":features.reindex(idx)}\n",
    "    raw_targets = np.array(labels[idx])\n",
    "   \n",
    "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "    return feature_batch, label_batch\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(features, labels, batch_size):\n",
    "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
    "\n",
    "  Args:\n",
    "    features: The features to base predictions on.\n",
    "    labels: The labels of the prediction examples.\n",
    "\n",
    "  Returns:\n",
    "    A function that returns features and labels for predictions.\n",
    "  \"\"\"\n",
    "  def _input_fn():\n",
    "    raw_features = {\"x\": features.values}\n",
    "    raw_targets = np.array(labels)\n",
    "    \n",
    "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Return the next batch of data.\n",
    "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "    return feature_batch, label_batch\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#     optimizer = tf.train.AdagradOptimizer(learning_rate=0.05)\n",
    "#     optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n",
    "#     optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[\"learning_rate\"])#learning_rate=0.001)\n",
    "    optimizer = params[\"optimizer\"]\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_cnn_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  a plot of the training and validation loss over time, as well as a confusion\n",
    "  matrix.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: An `int`, the learning rate to use.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
    "    training_examples: A `DataFrame` containing the training features.\n",
    "    training_targets: A `DataFrame` containing the training labels.\n",
    "    validation_examples: A `DataFrame` containing the validation features.\n",
    "    validation_targets: A `DataFrame` containing the validation labels.\n",
    "      \n",
    "  Returns:\n",
    "    The trained `CNNClassifier` object.\n",
    "  \"\"\"\n",
    "#log to terminal\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  periods = 10\n",
    "  # Caution: input pipelines are reset with each call to train. \n",
    "  # If the number of steps is small, your model may never see most of the data.  \n",
    "  # So with multiple `.train` calls like this you may want to control the length \n",
    "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
    "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
    "  steps_per_period = steps / periods  \n",
    "  \n",
    "  # Create the input functions.\n",
    "  predict_training_input_fn = create_predict_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  predict_validation_input_fn = create_predict_input_fn(\n",
    "    validation_examples, validation_targets, batch_size)\n",
    "  training_input_fn = create_training_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "\n",
    "  # Create feature columns.\n",
    "#   feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
    "\n",
    "  # Create a CNNClassifier object. ### Optimzer in cnn_model #####\n",
    "#   my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "#   my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "#   my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.05)\n",
    "#   my_optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n",
    "#   my_optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "  # Create the Estimator                        ## ADDED params so that I can pass values to model\n",
    "  classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_mode7\", params={\n",
    "        'learning_rate': learning_rate,\n",
    "        'optimizer' : my_optimizer,\n",
    "#         'feature_columns': my_feature_columns,\n",
    "#         # Two hidden layers of 10 nodes each.\n",
    "#         'hidden_units': [10, 10],\n",
    "#         # The model must choose between 3 classes.\n",
    "#         'n_classes': 3,\n",
    "    })\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"LogLoss error and accuracy (on validation data):\")\n",
    "  training_errors = []\n",
    "  validation_errors = []\n",
    "  for period in range (0, periods):\n",
    "  # Train the model, starting from the prior state.\n",
    "\n",
    "  # Train the model\n",
    "    classifier.train(\n",
    "          input_fn=training_input_fn,\n",
    "          steps=steps_per_period,#,#000,#20000,\n",
    "          hooks=[logging_hook]\n",
    "        )\n",
    "    \n",
    "    eval_results = classifier.evaluate(input_fn=predict_validation_input_fn)\n",
    "    print(eval_results)\n",
    "  \n",
    "    # Take a break and compute probabilities.\n",
    "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "    training_pred_class_id = np.array([item['classes'] for item in training_predictions])\n",
    "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
    "       \n",
    "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn)) \n",
    "    validation_pred_class_id = np.array([item['classes'] for item in validation_predictions])\n",
    "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)   \n",
    "    \n",
    "    # Compute training and validation errors.\n",
    "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f     Accuracy: %02f\" % (period, validation_log_loss, eval_results['accuracy']))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_errors.append(training_log_loss)\n",
    "    validation_errors.append(validation_log_loss)\n",
    "  print(\"Model training finished.\")\n",
    "  # Remove event files to save disk space.\n",
    "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "  \n",
    "  # Calculate final predictions (not probabilities, as above).\n",
    "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "  final_predictions = np.array([item['classes'] for item in final_predictions])\n",
    "  \n",
    "  \n",
    "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"LogLoss\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"LogLoss vs. Periods\")\n",
    "  plt.plot(training_errors, label=\"training\")\n",
    "  plt.plot(validation_errors, label=\"validation\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "  # Output a plot of the confusion matrix.\n",
    "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "  # in each class).\n",
    "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "  ax.set_aspect(1)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  plt.show()\n",
    "\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "4773     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1384     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1655     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "8843     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "5917     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "4617     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2353     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3415     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4471     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "159      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "      pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "4773     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "1384     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "1655     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "8843     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "5917     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "...      ...    ...          ...       ...       ...       ...       ...   \n",
      "4617     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "2353     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "3415     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "4471     0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "159      0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "      pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "4773       0.0       0.0       0.0       0.0       0.0  \n",
      "1384       0.0       0.0       0.0       0.0       0.0  \n",
      "1655       0.0       0.0       0.0       0.0       0.0  \n",
      "8843       0.0       0.0       0.0       0.0       0.0  \n",
      "5917       0.0       0.0       0.0       0.0       0.0  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "4617       0.0       0.0       0.0       0.0       0.0  \n",
      "2353       0.0       0.0       0.0       0.0       0.0  \n",
      "3415       0.0       0.0       0.0       0.0       0.0  \n",
      "4471       0.0       0.0       0.0       0.0       0.0  \n",
      "159        0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[7500 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error and accuracy (on validation data):\n",
      "{'global_step': 2000, 'loss': 0.5867178, 'accuracy': 0.8512}\n",
      "  period 00 : 5.14     Accuracy: 0.851200\n",
      "{'global_step': 4000, 'loss': 0.31157228, 'accuracy': 0.912}\n",
      "  period 01 : 3.04     Accuracy: 0.912000\n",
      "{'global_step': 6000, 'loss': 0.24010241, 'accuracy': 0.9316}\n",
      "  period 02 : 2.36     Accuracy: 0.931600\n",
      "{'global_step': 8000, 'loss': 0.2011945, 'accuracy': 0.94}\n",
      "  period 03 : 2.07     Accuracy: 0.940000\n",
      "{'global_step': 10000, 'loss': 0.17659006, 'accuracy': 0.9472}\n",
      "  period 04 : 1.82     Accuracy: 0.947200\n",
      "{'global_step': 12000, 'loss': 0.15939787, 'accuracy': 0.9496}\n",
      "  period 05 : 1.74     Accuracy: 0.949600\n",
      "{'global_step': 14000, 'loss': 0.145344, 'accuracy': 0.9552}\n",
      "  period 06 : 1.55     Accuracy: 0.955200\n",
      "{'global_step': 16000, 'loss': 0.1326399, 'accuracy': 0.9576}\n",
      "  period 07 : 1.46     Accuracy: 0.957600\n",
      "{'global_step': 18000, 'loss': 0.12371579, 'accuracy': 0.9608}\n",
      "  period 08 : 1.35     Accuracy: 0.960800\n",
      "{'global_step': 20000, 'loss': 0.11812456, 'accuracy': 0.9608}\n",
      "  period 09 : 1.35     Accuracy: 0.960800\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEZCAYAAABy91VnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n10+sFos7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ba960a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEZCAYAAAAHeunEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf6sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3baad60240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_classifier = train_cnn_classification_model(\n",
    "    learning_rate=0.001,#0.05,\n",
    "    steps=20000,#1000,\n",
    "    batch_size=100,\n",
    "    hidden_units=[5],#[100, 100],\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "count 28000.0 28000.0 28000.0 28000.0 28000.0 28000.0 28000.0 28000.0 28000.0   \n",
       "mean      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "std       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "min       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "25%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "50%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "75%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "max       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "count 28000.0    ...      28000.0   28000.0   28000.0   28000.0   28000.0   \n",
       "mean      0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "std       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "min       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "25%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "50%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "75%       0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
       "max       0.0    ...          1.0       1.0       0.8       0.7       0.5   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "count   28000.0   28000.0   28000.0   28000.0   28000.0  \n",
       "mean        0.0       0.0       0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_dataframe = pd.read_csv(\n",
    "  \"data/test.csv\",\n",
    "  sep=\",\")\n",
    "\n",
    "mnist_test_sample_dataframe = pd.read_csv(\n",
    "  \"data/sample_submission.csv\",\n",
    "  sep=\",\")\n",
    "\n",
    "# test_targets, test_examples = parse_test_labels_and_features(mnist_test_sample_dataframe, mnist_test_dataframe)#parse_labels_and_features(mnist_test_dataframe)\n",
    "\n",
    "\n",
    "# test_examples =   features = dataset.iloc[:,1:785]\n",
    "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
    "#   features = features // 255\n",
    "#   features = features.applymap(lambda x: x / 255)\n",
    "\n",
    "test_examples = mnist_test_dataframe.copy().applymap(lambda x: x / 255)\n",
    "# print(mnist_test_sample_dataframe)\n",
    "test_targets = mnist_test_sample_dataframe['Label'].copy()\n",
    "test_examples.describe()\n",
    "# test_targets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.10\n"
     ]
    }
   ],
   "source": [
    "predict_test_input_fn = create_predict_input_fn(\n",
    "    test_examples, test_targets, batch_size=100)\n",
    "\n",
    "test_predictions = cnn_classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "  \n",
    "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
    "print(\"Accuracy on test data: %0.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "       ImageId  Label\n",
      "0            1      2\n",
      "1            2      0\n",
      "2            3      9\n",
      "3            4      9\n",
      "4            5      3\n",
      "...        ...    ...\n",
      "27995    27996      9\n",
      "27996    27997      7\n",
      "27997    27998      3\n",
      "27998    27999      9\n",
      "27999    28000      2\n",
      "\n",
      "[28000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_predictions))\n",
    "new = pd.DataFrame(test_predictions, columns=[\"Label\"])#[1], index=new_predictions[0])\n",
    "# print(new)\n",
    "# new.index.name = \"ImageId\"\n",
    "new = pd.concat([mnist_test_sample_dataframe['ImageId'], new], axis=1)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new.to_csv('predictions7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Visualize weights of first hidden layer\n",
    "# print(cnn_classifier.get_variable_names())\n",
    "\n",
    "# weights0 = cnn_classifier.get_variable_value(\"/tmp/mnist_convnet_mode2/hiddenlayer_0/kernel\");#dnn/hiddenlayer_0/kernel\")\n",
    "\n",
    "# print(\"weights0 shape:\", weights0.shape)\n",
    "\n",
    "# num_nodes = weights0.shape[1]\n",
    "# num_rows = int(math.ceil(num_nodes / 10.0))\n",
    "# fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
    "# for coef, ax in zip(weights0.T, axes.ravel()):\n",
    "#     # Weights in coef is reshaped from 1x784 to 28x28.\n",
    "#     ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
    "#     ax.set_xticks(())\n",
    "#     ax.set_yticks(())\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cnn_model_fn(features, labels, mode):\n",
    "#   \"\"\"Model function for CNN.\"\"\"\n",
    "#   # Input Layer\n",
    "#   # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "#   # MNIST images are 28x28 pixels, and have one color channel\n",
    "#   input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "#   # Convolutional Layer #1\n",
    "#   # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "#   # Padding is added to preserve width and height.\n",
    "#   # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "#   # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "#   conv1 = tf.layers.conv2d(\n",
    "#       inputs=input_layer,\n",
    "#       filters=32,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "\n",
    "#   # Pooling Layer #1\n",
    "#   # First max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "#   # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "#   pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#   # Convolutional Layer #2\n",
    "#   # Computes 64 features using a 5x5 filter.\n",
    "#   # Padding is added to preserve width and height.\n",
    "#   # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "#   # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "#   conv2 = tf.layers.conv2d(\n",
    "#       inputs=pool1,\n",
    "#       filters=64,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "\n",
    "#   # Pooling Layer #2\n",
    "#   # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "#   pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#   # Flatten tensor into a batch of vectors\n",
    "#   # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "#   pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "#   # Dense Layer\n",
    "#   # Densely connected layer with 1024 neurons\n",
    "#   # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "#   # Output Tensor Shape: [batch_size, 1024]\n",
    "#   dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "#   # Add dropout operation; 0.6 probability that element will be kept\n",
    "#   dropout = tf.layers.dropout(\n",
    "#       inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "#   # Logits layer\n",
    "#   # Input Tensor Shape: [batch_size, 1024]\n",
    "#   # Output Tensor Shape: [batch_size, 10]\n",
    "#   logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "#   predictions = {\n",
    "#       # Generate predictions (for PREDICT and EVAL mode)\n",
    "#       \"classes\": tf.argmax(input=logits, axis=1),\n",
    "#       # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "#       # `logging_hook`.\n",
    "#       \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "#   }\n",
    "#   if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "#   # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "#   loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "#   # Configure the Training Op (for TRAIN mode)\n",
    "#   if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#     train_op = optimizer.minimize(\n",
    "#         loss=loss,\n",
    "#         global_step=tf.train.get_global_step())\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "#   # Add evaluation metrics (for EVAL mode)\n",
    "#   eval_metric_ops = {\n",
    "#       \"accuracy\": tf.metrics.accuracy(\n",
    "#           labels=labels, predictions=predictions[\"classes\"])}\n",
    "#   return tf.estimator.EstimatorSpec(\n",
    "#       mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # def main(unused_argv):\n",
    "# # Load training and eval data\n",
    "# VALID = 10000 # Validation data size\n",
    "\n",
    "# LABELS = 10 # Number of different types of labels (1-10)\n",
    "# WIDTH = 28 # width / height of the image\n",
    "# CHANNELS = 1 # Number of colors in the image (greyscale)\n",
    "# data = pd.read_csv('data/train.csv') # Read csv file in pandas dataframe\n",
    "# labels = np.array(data.pop('label')) # Remove the labels as a numpy array from the dataframe\n",
    "# #   labels = LabelEncoder().fit_transform(labels)[:, None]\n",
    "# #   labels = OneHotEncoder().fit_transform(labels).todense()\n",
    "# data = StandardScaler().fit_transform(np.float32(data.values)) # Convert the dataframe to a numpy array\n",
    "# #   data = data.reshape(-1, WIDTH, WIDTH, CHANNELS) # Reshape the data into 42000 2d images\n",
    "# train_data, eval_data = data[:-VALID], data[-VALID:]\n",
    "# train_labels, eval_labels = labels[:-VALID], labels[-VALID:]\n",
    "\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# #   mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "# #   train_data = mnist.train.images  # Returns np.array\n",
    "# #   train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "# #   eval_data = mnist.test.images  # Returns np.array\n",
    "# #   eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# # Create the Estimator\n",
    "# mnist_classifier = tf.estimator.Estimator(\n",
    "#   model_fn=cnn_model_fn, model_dir=\"~/delete/one\")#/tmp/mnist_convnet_model\")\n",
    "\n",
    "# # # Set up logging for predictions\n",
    "# # # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "# # tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "# # logging_hook = tf.train.LoggingTensorHook(\n",
    "# #   tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# # Train the model\n",
    "# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#   x={\"x\": train_data},\n",
    "#   y=train_labels,\n",
    "#   batch_size=100,\n",
    "#   num_epochs=None,\n",
    "#   shuffle=True)\n",
    "# mnist_classifier.train(\n",
    "#   input_fn=train_input_fn,\n",
    "#   steps=5#,#000,#20000,\n",
    "# #   hooks=[logging_hook]\n",
    "# )\n",
    "\n",
    "# # Evaluate the model and print results\n",
    "# eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#   x={\"x\": eval_data},\n",
    "#   y=eval_labels,\n",
    "#   num_epochs=1,\n",
    "#   shuffle=False)\n",
    "# eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "# print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "# #\n",
    "# #  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# #  you may not use this file except in compliance with the License.\n",
    "# #  You may obtain a copy of the License at\n",
    "# #\n",
    "# #   http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# #  Unless required by applicable law or agreed to in writing, software\n",
    "# #  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# #  See the License for the specific language governing permissions and\n",
    "# #  limitations under the License.\n",
    "# \"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "# def cnn_model_fn(features, labels, mode):\n",
    "#   \"\"\"Model function for CNN.\"\"\"\n",
    "#   # Input Layer\n",
    "#   # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "#   # MNIST images are 28x28 pixels, and have one color channel\n",
    "#   input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "#   # Convolutional Layer #1\n",
    "#   # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "#   # Padding is added to preserve width and height.\n",
    "#   # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "#   # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "#   conv1 = tf.layers.conv2d(\n",
    "#       inputs=input_layer,\n",
    "#       filters=32,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "\n",
    "#   # Pooling Layer #1\n",
    "#   # First max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "#   # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "#   pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#   # Convolutional Layer #2\n",
    "#   # Computes 64 features using a 5x5 filter.\n",
    "#   # Padding is added to preserve width and height.\n",
    "#   # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "#   # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "#   conv2 = tf.layers.conv2d(\n",
    "#       inputs=pool1,\n",
    "#       filters=64,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "\n",
    "#   # Pooling Layer #2\n",
    "#   # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "#   pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#   # Flatten tensor into a batch of vectors\n",
    "#   # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "#   pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "#   # Dense Layer\n",
    "#   # Densely connected layer with 1024 neurons\n",
    "#   # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "#   # Output Tensor Shape: [batch_size, 1024]\n",
    "#   dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "#   # Add dropout operation; 0.6 probability that element will be kept\n",
    "#   dropout = tf.layers.dropout(\n",
    "#       inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "#   # Logits layer\n",
    "#   # Input Tensor Shape: [batch_size, 1024]\n",
    "#   # Output Tensor Shape: [batch_size, 10]\n",
    "#   logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "#   predictions = {\n",
    "#       # Generate predictions (for PREDICT and EVAL mode)\n",
    "#       \"classes\": tf.argmax(input=logits, axis=1),\n",
    "#       # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "#       # `logging_hook`.\n",
    "#       \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "#   }\n",
    "#   if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "#   # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "#   loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "#   # Configure the Training Op (for TRAIN mode)\n",
    "#   if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#     train_op = optimizer.minimize(\n",
    "#         loss=loss,\n",
    "#         global_step=tf.train.get_global_step())\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "#   # Add evaluation metrics (for EVAL mode)\n",
    "#   eval_metric_ops = {\n",
    "#       \"accuracy\": tf.metrics.accuracy(\n",
    "#           labels=labels, predictions=predictions[\"classes\"])}\n",
    "#   return tf.estimator.EstimatorSpec(\n",
    "#       mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "# def main(unused_argv):\n",
    "#   # Load training and eval data\n",
    "#   mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "#   train_data = mnist.train.images  # Returns np.array\n",
    "#   train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "#   eval_data = mnist.test.images  # Returns np.array\n",
    "#   eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "#   # Create the Estimator\n",
    "#   mnist_classifier = tf.estimator.Estimator(\n",
    "#       model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "#   # Set up logging for predictions\n",
    "#   # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "#   tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#   logging_hook = tf.train.LoggingTensorHook(\n",
    "#       tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "#   # Train the model\n",
    "#   train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": train_data},\n",
    "#       y=train_labels,\n",
    "#       batch_size=100,\n",
    "#       num_epochs=None,\n",
    "#       shuffle=True)\n",
    "#   mnist_classifier.train(\n",
    "#       input_fn=train_input_fn,\n",
    "#       steps=20000,\n",
    "#       hooks=[logging_hook])\n",
    "\n",
    "#   # Evaluate the model and print results\n",
    "#   eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": eval_data},\n",
    "#       y=eval_labels,\n",
    "#       num_epochs=1,\n",
    "#       shuffle=False)\n",
    "#   eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "#   print(eval_results)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
